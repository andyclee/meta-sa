Namespace(arch='cnn', data_dir='embs', disk_load=False, embdim=100, epoch=60000, k_qry=15, k_spt=1, meta_lr=0.001, n_way=5, task_num=4, test_batchsz=100, train_batchsz=10000, update_lr=0.001, update_step=5, update_step_test=10)
Meta(
  (net): Learner(
    conv1d:(ch_out:32, ch_in:1, k:3, stride:1, padding:same)
    elu:(False,)
    conv1d:(ch_out:32, ch_in:32, k:3, stride:1, padding:same)
    elu:(False,)
    max_pool1d:(pool_size:2)
    dense:(ch_out:128, ch_in:1600)
    tanh:()
    dropout:(0.4, False)
    dense:(ch_out:5, ch_in:128)
    
    (vars): ParameterList(
        (0): Parameter containing: [torch.float32 of size 32x1x3 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 32x32x3 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 128x1600 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 128 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 5x128 (GPU 0)]
        (7): Parameter containing: [torch.float32 of size 5 (GPU 0)]
    )
    (vars_bn): ParameterList()
  )
)
Total trainable tensors: 208805
step: 0 	training acc: [0.19666667 0.23333333 0.20333333 0.18333333 0.22666667 0.22333333]
/home/andy2/scratch/mypython3/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
Meta-test acc: [0.199  0.1938 0.1874 0.19   0.1986 0.1858 0.189  0.1897 0.1907 0.1852
 0.1884]
step: 30 	training acc: [0.17333333 0.18       0.18666667 0.17       0.19333333 0.21333333]
step: 60 	training acc: [0.2        0.22       0.19333333 0.23333333 0.21666667 0.22333333]
step: 90 	training acc: [0.26333333 0.26333333 0.26       0.25333333 0.25666667 0.24      ]
step: 120 	training acc: [0.23       0.20666667 0.22       0.19666667 0.21666667 0.22333333]
step: 150 	training acc: [0.18666667 0.18       0.16       0.15333333 0.17       0.16333333]
step: 180 	training acc: [0.20333333 0.19666667 0.21       0.20666667 0.2        0.20333333]
step: 210 	training acc: [0.28666667 0.29333333 0.28       0.28333333 0.31       0.29666667]
step: 240 	training acc: [0.17       0.23666667 0.20333333 0.19       0.18333333 0.19666667]
step: 270 	training acc: [0.15       0.18       0.16666667 0.16       0.15333333 0.16      ]
step: 300 	training acc: [0.19333333 0.22333333 0.20666667 0.19333333 0.21       0.20666667]
step: 330 	training acc: [0.30333333 0.32666667 0.30666667 0.30666667 0.36       0.32666667]
step: 360 	training acc: [0.25666667 0.23666667 0.24333333 0.24333333 0.27       0.27      ]
step: 390 	training acc: [0.17333333 0.15       0.16666667 0.15333333 0.15666667 0.15333333]
step: 420 	training acc: [0.26333333 0.25333333 0.27333333 0.25       0.26       0.23333333]
step: 450 	training acc: [0.17       0.21       0.18       0.19666667 0.18666667 0.19333333]
step: 480 	training acc: [0.4        0.41666667 0.4        0.41       0.42666667 0.43      ]
Meta-test acc: [0.1974 0.1982 0.199  0.1979 0.2024 0.1957 0.1996 0.2017 0.2013 0.2026
 0.1992]
step: 510 	training acc: [0.11       0.16       0.12       0.11666667 0.10666667 0.13      ]
step: 540 	training acc: [0.2        0.20666667 0.24666667 0.20333333 0.20333333 0.20333333]
step: 570 	training acc: [0.14666667 0.14333333 0.13       0.15666667 0.16333333 0.14      ]
step: 600 	training acc: [0.11666667 0.13       0.12       0.12666667 0.13333333 0.11333333]
step: 630 	training acc: [0.17333333 0.16       0.18       0.17       0.16666667 0.17      ]
step: 660 	training acc: [0.25       0.28666667 0.27       0.27666667 0.27333333 0.27      ]
step: 690 	training acc: [0.40333333 0.37333333 0.34666667 0.41666667 0.39333333 0.40333333]
step: 720 	training acc: [0.34666667 0.36333333 0.33666667 0.37333333 0.35       0.37666667]
step: 750 	training acc: [0.19666667 0.22333333 0.23       0.20333333 0.22333333 0.21      ]
step: 780 	training acc: [0.24333333 0.23       0.22333333 0.23333333 0.22666667 0.23      ]
step: 810 	training acc: [0.13333333 0.14333333 0.14333333 0.15       0.14       0.14333333]
step: 840 	training acc: [0.14       0.13666667 0.08666667 0.11666667 0.12       0.09666667]
step: 870 	training acc: [0.11333333 0.10333333 0.10666667 0.1        0.1        0.09      ]
step: 900 	training acc: [0.11666667 0.11333333 0.11       0.13       0.14666667 0.11666667]
step: 930 	training acc: [0.10666667 0.09       0.1        0.09       0.08333333 0.09333333]
step: 960 	training acc: [0.32       0.32666667 0.31666667 0.31       0.32333333 0.31666667]
step: 990 	training acc: [0.18333333 0.19666667 0.17       0.16       0.18666667 0.18666667]
Meta-test acc: [0.1868 0.1903 0.1902 0.1865 0.1898 0.1908 0.1896 0.1907 0.1902 0.1865
 0.19  ]
step: 1020 	training acc: [0.19666667 0.21       0.21       0.21       0.21333333 0.20333333]
step: 1050 	training acc: [0.13       0.10666667 0.11       0.12333333 0.11333333 0.09666667]
step: 1080 	training acc: [0.19333333 0.16666667 0.17       0.18333333 0.13666667 0.16      ]
step: 1110 	training acc: [0.41666667 0.39       0.40333333 0.41333333 0.39666667 0.39666667]
step: 1140 	training acc: [0.16666667 0.2        0.17666667 0.17       0.18333333 0.18      ]
step: 1170 	training acc: [0.22666667 0.24333333 0.20666667 0.20333333 0.20666667 0.20333333]
step: 1200 	training acc: [0.32666667 0.3        0.30333333 0.28666667 0.31666667 0.33      ]
step: 1230 	training acc: [0.28       0.28333333 0.27666667 0.26666667 0.27       0.27      ]
step: 1260 	training acc: [0.29333333 0.27333333 0.27666667 0.24666667 0.27       0.3       ]
step: 1290 	training acc: [0.17666667 0.19333333 0.18666667 0.2        0.2        0.19333333]
step: 1320 	training acc: [0.15       0.16       0.17333333 0.16       0.19       0.16      ]
step: 1350 	training acc: [0.08333333 0.08       0.08333333 0.07       0.07666667 0.08      ]
step: 1380 	training acc: [0.15333333 0.14333333 0.15       0.15       0.14333333 0.15666667]
step: 1410 	training acc: [0.16666667 0.16666667 0.16666667 0.19333333 0.17333333 0.17      ]
step: 1440 	training acc: [0.10333333 0.13       0.12       0.10666667 0.13       0.11      ]
step: 1470 	training acc: [0.30666667 0.30333333 0.32333333 0.32333333 0.36       0.32333333]
step: 1500 	training acc: [0.25666667 0.26       0.26       0.27333333 0.28       0.27      ]
Meta-test acc: [0.1711 0.1726 0.1738 0.1735 0.1733 0.1722 0.1707 0.171  0.173  0.1752
 0.1685]
step: 1530 	training acc: [0.18333333 0.16666667 0.21       0.18333333 0.17666667 0.20333333]
step: 1560 	training acc: [0.08333333 0.09333333 0.08       0.08       0.07666667 0.08      ]
step: 1590 	training acc: [0.22666667 0.25       0.25666667 0.23666667 0.24       0.24      ]
step: 1620 	training acc: [0.26       0.24666667 0.25       0.25333333 0.25666667 0.24      ]
step: 1650 	training acc: [0.26666667 0.26       0.26333333 0.26666667 0.27333333 0.25666667]
step: 1680 	training acc: [0.23666667 0.24       0.22       0.24       0.23333333 0.22333333]
step: 1710 	training acc: [0.24333333 0.24666667 0.24333333 0.22333333 0.24333333 0.25      ]
step: 1740 	training acc: [0.08       0.09666667 0.1        0.08666667 0.08666667 0.13333333]
step: 1770 	training acc: [0.31       0.31666667 0.33666667 0.29       0.30333333 0.32      ]
step: 1800 	training acc: [0.23333333 0.24333333 0.24666667 0.25333333 0.24333333 0.23666667]
step: 1830 	training acc: [0.27       0.27333333 0.28       0.27333333 0.29333333 0.27333333]
step: 1860 	training acc: [0.2        0.21333333 0.21333333 0.21333333 0.21666667 0.22333333]
step: 1890 	training acc: [0.28       0.25333333 0.27       0.26       0.27666667 0.29666667]
step: 1920 	training acc: [0.15666667 0.17       0.14666667 0.16       0.16666667 0.16      ]
step: 1950 	training acc: [0.23666667 0.27       0.27       0.29333333 0.25666667 0.26666667]
step: 1980 	training acc: [0.20666667 0.21666667 0.2        0.20666667 0.21       0.24333333]
Meta-test acc: [0.1782 0.1815 0.1786 0.178  0.1796 0.1749 0.1766 0.1769 0.1821 0.1808
 0.1774]
step: 2010 	training acc: [0.23       0.23666667 0.26333333 0.24666667 0.23666667 0.22      ]
step: 2040 	training acc: [0.12333333 0.1        0.12333333 0.11666667 0.10333333 0.11666667]
step: 2070 	training acc: [0.27333333 0.25666667 0.25333333 0.25       0.27333333 0.25666667]
step: 2100 	training acc: [0.12       0.14666667 0.13333333 0.16333333 0.14666667 0.12666667]
step: 2130 	training acc: [0.13       0.11666667 0.13       0.12666667 0.12333333 0.15      ]
step: 2160 	training acc: [0.16       0.15333333 0.15666667 0.17333333 0.16666667 0.14333333]
step: 2190 	training acc: [0.12333333 0.09666667 0.10666667 0.12666667 0.12333333 0.13333333]
step: 2220 	training acc: [0.22666667 0.23       0.22333333 0.23       0.22333333 0.23666667]
step: 2250 	training acc: [0.15       0.14333333 0.15       0.12       0.15666667 0.14666667]
step: 2280 	training acc: [0.30666667 0.33333333 0.31333333 0.35333333 0.32       0.33333333]
step: 2310 	training acc: [0.29       0.33333333 0.27333333 0.31333333 0.29666667 0.32      ]
step: 2340 	training acc: [0.11333333 0.10666667 0.09333333 0.10666667 0.10666667 0.1       ]
step: 2370 	training acc: [0.23       0.22333333 0.25       0.22666667 0.25333333 0.23333333]
step: 2400 	training acc: [0.19333333 0.19333333 0.19       0.19333333 0.19       0.18      ]
step: 2430 	training acc: [0.25666667 0.25666667 0.25333333 0.25666667 0.28666667 0.26666667]
step: 2460 	training acc: [0.19       0.19       0.2        0.21       0.22       0.18333333]
step: 2490 	training acc: [0.21666667 0.16666667 0.20666667 0.18666667 0.19       0.18333333]
step: 0 	training acc: [0.25333333 0.25       0.27333333 0.28       0.25666667 0.27666667]
Meta-test acc: [0.1931 0.1946 0.1927 0.1924 0.1926 0.1909 0.1919 0.1918 0.1936 0.1921
 0.1919]
step: 30 	training acc: [0.31333333 0.3        0.25       0.27333333 0.27       0.27333333]
step: 60 	training acc: [0.17666667 0.19       0.18666667 0.18       0.18666667 0.18333333]
step: 90 	training acc: [0.23666667 0.25       0.24333333 0.22       0.20333333 0.22666667]
step: 120 	training acc: [0.21333333 0.24       0.22666667 0.22       0.20666667 0.22666667]
step: 150 	training acc: [0.24666667 0.25       0.23333333 0.26666667 0.25666667 0.24666667]
step: 180 	training acc: [0.43333333 0.41666667 0.43333333 0.40333333 0.41       0.46333333]
step: 210 	training acc: [0.27       0.26333333 0.25666667 0.27333333 0.25666667 0.25333333]
step: 240 	training acc: [0.19       0.18       0.18       0.17333333 0.18       0.17333333]
step: 270 	training acc: [0.21666667 0.17       0.19333333 0.18       0.18666667 0.17666667]
step: 300 	training acc: [0.13666667 0.12       0.11666667 0.08333333 0.13666667 0.11333333]
step: 330 	training acc: [0.16666667 0.19       0.18       0.16333333 0.16666667 0.18      ]
step: 360 	training acc: [0.38666667 0.39666667 0.38333333 0.36       0.38       0.38      ]
step: 390 	training acc: [0.16666667 0.18666667 0.17333333 0.16333333 0.18666667 0.16666667]
step: 420 	training acc: [0.31333333 0.31666667 0.31666667 0.27       0.29333333 0.29666667]
step: 450 	training acc: [0.24666667 0.21333333 0.24       0.24       0.24666667 0.22333333]
step: 480 	training acc: [0.18       0.17666667 0.17       0.17666667 0.16333333 0.16333333]
Meta-test acc: [0.2323 0.231  0.2325 0.2358 0.2303 0.2311 0.2269 0.2338 0.2324 0.2325
 0.2355]
step: 510 	training acc: [0.20333333 0.17       0.19       0.19333333 0.17333333 0.18333333]
step: 540 	training acc: [0.21333333 0.17666667 0.18333333 0.17666667 0.2        0.19      ]
step: 570 	training acc: [0.15       0.15333333 0.15       0.18       0.15       0.16333333]
step: 600 	training acc: [0.19666667 0.19666667 0.18333333 0.18666667 0.18       0.16      ]
step: 630 	training acc: [0.19666667 0.18666667 0.2        0.20666667 0.22333333 0.18333333]
step: 660 	training acc: [0.16       0.14333333 0.15333333 0.15666667 0.18       0.17666667]
step: 690 	training acc: [0.29       0.26       0.27       0.32       0.29666667 0.29333333]
step: 720 	training acc: [0.26666667 0.26       0.23       0.25       0.24333333 0.26333333]
step: 750 	training acc: [0.09666667 0.09333333 0.09333333 0.08333333 0.09333333 0.06666667]
step: 780 	training acc: [0.18       0.18666667 0.17666667 0.17666667 0.18333333 0.17333333]
step: 810 	training acc: [0.10333333 0.09666667 0.09       0.10333333 0.09       0.09      ]
step: 840 	training acc: [0.2        0.22333333 0.21       0.22333333 0.19666667 0.21666667]
step: 870 	training acc: [0.36666667 0.37666667 0.37333333 0.37333333 0.36       0.38666667]
step: 900 	training acc: [0.26       0.24666667 0.24666667 0.24333333 0.26666667 0.24      ]
step: 930 	training acc: [0.19666667 0.15       0.17666667 0.17666667 0.16       0.18666667]
step: 960 	training acc: [0.20666667 0.2        0.21333333 0.22       0.21       0.21333333]
step: 990 	training acc: [0.11666667 0.09333333 0.09666667 0.10333333 0.09333333 0.10333333]
Meta-test acc: [0.1896 0.1864 0.185  0.189  0.1887 0.189  0.1869 0.1892 0.1858 0.1864
 0.1875]
step: 1020 	training acc: [0.20666667 0.20666667 0.21666667 0.17       0.19       0.20666667]
step: 1050 	training acc: [0.16666667 0.17666667 0.18       0.19333333 0.16666667 0.16333333]
step: 1080 	training acc: [0.27666667 0.25666667 0.29333333 0.25       0.27666667 0.27666667]
step: 1110 	training acc: [0.18       0.19333333 0.19666667 0.18       0.19666667 0.19      ]
step: 1140 	training acc: [0.15666667 0.13666667 0.13       0.13       0.11333333 0.1       ]
step: 1170 	training acc: [0.27666667 0.26333333 0.29333333 0.27       0.28       0.27666667]
step: 1200 	training acc: [0.19       0.17666667 0.19       0.16       0.16666667 0.18333333]
step: 1230 	training acc: [0.26666667 0.22333333 0.24       0.23       0.20666667 0.23666667]
step: 1260 	training acc: [0.1        0.10333333 0.11       0.10333333 0.09       0.09666667]
step: 1290 	training acc: [0.19       0.17       0.17333333 0.18666667 0.18666667 0.18333333]
step: 1320 	training acc: [0.21       0.22333333 0.21333333 0.22333333 0.23666667 0.22      ]
step: 1350 	training acc: [0.26666667 0.24333333 0.28333333 0.24666667 0.29333333 0.27666667]
step: 1380 	training acc: [0.22       0.20333333 0.22333333 0.22       0.21666667 0.22      ]
step: 1410 	training acc: [0.14       0.14666667 0.14333333 0.14       0.14666667 0.15333333]
step: 1440 	training acc: [0.25666667 0.24666667 0.26       0.26666667 0.28333333 0.26      ]
step: 1470 	training acc: [0.27666667 0.26       0.29       0.27       0.3        0.27666667]
step: 1500 	training acc: [0.20666667 0.2        0.26       0.23       0.23       0.23666667]
Meta-test acc: [0.186  0.194  0.1893 0.1907 0.19   0.1934 0.1925 0.1913 0.1904 0.1959
 0.1907]
step: 1530 	training acc: [0.08333333 0.09333333 0.09666667 0.09       0.08333333 0.08666667]
step: 1560 	training acc: [0.28333333 0.24666667 0.25       0.24333333 0.25333333 0.27333333]
step: 1590 	training acc: [0.39666667 0.38666667 0.39       0.43       0.39       0.39666667]
step: 1620 	training acc: [0.20333333 0.21       0.18666667 0.20333333 0.23333333 0.20333333]
step: 1650 	training acc: [0.19       0.18       0.15       0.20666667 0.15666667 0.21      ]
step: 1680 	training acc: [0.15       0.14333333 0.18       0.18       0.15333333 0.15      ]
step: 1710 	training acc: [0.12333333 0.13333333 0.12666667 0.11666667 0.12333333 0.11666667]
step: 1740 	training acc: [0.11333333 0.12666667 0.11       0.12666667 0.12333333 0.14666667]
step: 1770 	training acc: [0.06666667 0.03666667 0.06       0.06333333 0.08       0.05      ]
step: 1800 	training acc: [0.10333333 0.08333333 0.1        0.08666667 0.08       0.10666667]
step: 1830 	training acc: [0.27       0.26666667 0.25666667 0.26333333 0.24666667 0.28      ]
step: 1860 	training acc: [0.10333333 0.13666667 0.13666667 0.12333333 0.12666667 0.15333333]
step: 1890 	training acc: [0.13333333 0.15       0.13333333 0.13666667 0.16666667 0.16      ]
step: 1920 	training acc: [0.30666667 0.28333333 0.28333333 0.29       0.3        0.32      ]
step: 1950 	training acc: [0.21       0.19       0.23333333 0.20666667 0.19666667 0.18      ]
step: 1980 	training acc: [0.05333333 0.05333333 0.05666667 0.05333333 0.05333333 0.06      ]
Meta-test acc: [0.1945 0.1937 0.1912 0.1896 0.189  0.1914 0.189  0.195  0.1902 0.1941
 0.1888]
step: 2010 	training acc: [0.13       0.13666667 0.14333333 0.13333333 0.15       0.14333333]
step: 2040 	training acc: [0.28666667 0.26666667 0.26       0.22333333 0.26333333 0.25666667]
step: 2070 	training acc: [0.23333333 0.24666667 0.23666667 0.23666667 0.23333333 0.23333333]
step: 2100 	training acc: [0.18333333 0.19333333 0.18666667 0.19333333 0.18333333 0.17666667]
step: 2130 	training acc: [0.19666667 0.19666667 0.19333333 0.18333333 0.19666667 0.19666667]
step: 2160 	training acc: [0.12333333 0.14666667 0.12666667 0.14       0.14666667 0.12666667]
step: 2190 	training acc: [0.33       0.31       0.32333333 0.32333333 0.33666667 0.32666667]
step: 2220 	training acc: [0.13333333 0.14333333 0.12333333 0.14333333 0.12       0.12666667]
step: 2250 	training acc: [0.14666667 0.16       0.12333333 0.16333333 0.15333333 0.16666667]
step: 2280 	training acc: [0.22333333 0.24333333 0.25333333 0.23       0.26333333 0.25      ]
step: 2310 	training acc: [0.09       0.04666667 0.06       0.07       0.06666667 0.05      ]
step: 2340 	training acc: [0.14333333 0.12333333 0.11666667 0.10333333 0.11333333 0.12333333]
step: 2370 	training acc: [0.18333333 0.16       0.17333333 0.19666667 0.18333333 0.17666667]
step: 2400 	training acc: [0.12333333 0.10333333 0.15333333 0.1        0.12666667 0.12666667]
step: 2430 	training acc: [0.24       0.24       0.27333333 0.23666667 0.22666667 0.23      ]
step: 2460 	training acc: [0.35       0.35       0.35       0.36       0.34333333 0.35      ]
step: 2490 	training acc: [0.31       0.25666667 0.26       0.28333333 0.28       0.30333333]
step: 0 	training acc: [0.38333333 0.38       0.38       0.38       0.39       0.39333333]
Meta-test acc: [0.2014 0.1984 0.2023 0.1989 0.1986 0.2007 0.1991 0.1982 0.2008 0.1985
 0.2034]
step: 30 	training acc: [0.05333333 0.02666667 0.04666667 0.03333333 0.02       0.03      ]
step: 60 	training acc: [0.15666667 0.18666667 0.21333333 0.22666667 0.22666667 0.17      ]
step: 90 	training acc: [0.30666667 0.30666667 0.29666667 0.26666667 0.28       0.29333333]
step: 120 	training acc: [0.14       0.15       0.15333333 0.14       0.16       0.16666667]
step: 150 	training acc: [0.17       0.18333333 0.18333333 0.20333333 0.19       0.17666667]
step: 180 	training acc: [0.19       0.19333333 0.17666667 0.18666667 0.18666667 0.19      ]
step: 210 	training acc: [0.07       0.08       0.09       0.07333333 0.09333333 0.09666667]
step: 240 	training acc: [0.17666667 0.18333333 0.19333333 0.18333333 0.20666667 0.17333333]
step: 270 	training acc: [0.18333333 0.18333333 0.16666667 0.15666667 0.16333333 0.17333333]
step: 300 	training acc: [0.22333333 0.22       0.21666667 0.23       0.22666667 0.21      ]
step: 330 	training acc: [0.32666667 0.34       0.34666667 0.37333333 0.34       0.36      ]
step: 360 	training acc: [0.25       0.22666667 0.25       0.28333333 0.26666667 0.24333333]
step: 390 	training acc: [0.17333333 0.17       0.16666667 0.17666667 0.16333333 0.17      ]
step: 420 	training acc: [0.24666667 0.22       0.21666667 0.22333333 0.21666667 0.23333333]
step: 450 	training acc: [0.32       0.31333333 0.34333333 0.33333333 0.34       0.32666667]
step: 480 	training acc: [0.24333333 0.22666667 0.24666667 0.24333333 0.24333333 0.22666667]
Meta-test acc: [0.1906 0.1852 0.1892 0.1876 0.1895 0.1897 0.191  0.1902 0.1931 0.1896
 0.1888]
step: 510 	training acc: [0.23       0.21666667 0.21       0.23       0.20666667 0.22      ]
step: 540 	training acc: [0.22333333 0.21       0.21       0.22       0.21       0.2       ]
step: 570 	training acc: [0.20333333 0.25666667 0.21666667 0.22666667 0.21       0.20666667]
step: 600 	training acc: [0.13666667 0.12333333 0.11666667 0.11333333 0.11333333 0.11      ]
step: 630 	training acc: [0.34       0.29       0.29       0.27666667 0.27       0.30666667]
step: 660 	training acc: [0.15       0.15       0.15       0.14       0.16666667 0.15666667]
step: 690 	training acc: [0.17       0.14333333 0.15666667 0.15666667 0.17       0.14666667]
step: 720 	training acc: [0.16666667 0.13333333 0.14666667 0.16333333 0.15666667 0.15666667]
step: 750 	training acc: [0.17333333 0.19       0.19666667 0.17       0.18333333 0.18666667]
step: 780 	training acc: [0.37333333 0.28333333 0.33333333 0.32666667 0.31       0.31333333]
step: 810 	training acc: [0.17666667 0.17666667 0.19       0.18666667 0.17666667 0.22666667]
step: 840 	training acc: [0.15666667 0.18666667 0.16666667 0.17333333 0.13666667 0.21666667]
step: 870 	training acc: [0.31       0.32666667 0.30666667 0.32666667 0.33333333 0.36333333]
step: 900 	training acc: [0.21666667 0.20333333 0.23       0.21666667 0.21       0.2       ]
step: 930 	training acc: [0.06666667 0.07       0.06333333 0.06333333 0.06       0.06      ]
step: 960 	training acc: [0.29666667 0.28333333 0.29666667 0.25333333 0.23333333 0.26333333]
step: 990 	training acc: [0.28666667 0.30666667 0.29       0.29       0.29       0.31666667]
Meta-test acc: [0.2155 0.2178 0.215  0.2164 0.217  0.213  0.2135 0.2123 0.2144 0.2156
 0.217 ]
step: 1020 	training acc: [0.14666667 0.15333333 0.13       0.15       0.14333333 0.14666667]
step: 1050 	training acc: [0.18666667 0.17666667 0.21333333 0.21666667 0.19666667 0.21      ]
step: 1080 	training acc: [0.1        0.08333333 0.11333333 0.10666667 0.11       0.10333333]
step: 1110 	training acc: [0.27       0.30333333 0.30666667 0.28333333 0.29666667 0.3       ]
step: 1140 	training acc: [0.15333333 0.14666667 0.18333333 0.18333333 0.18333333 0.17      ]
step: 1170 	training acc: [0.20333333 0.22       0.17       0.19666667 0.23333333 0.23666667]
step: 1200 	training acc: [0.11666667 0.14666667 0.16666667 0.17       0.17666667 0.15666667]
step: 1230 	training acc: [0.09       0.06666667 0.05666667 0.07666667 0.06666667 0.07      ]
step: 1260 	training acc: [0.1        0.10333333 0.09       0.09333333 0.06333333 0.07333333]
step: 1290 	training acc: [0.23666667 0.26       0.23333333 0.21       0.24333333 0.25666667]
step: 1320 	training acc: [0.18666667 0.21666667 0.15666667 0.24666667 0.2        0.21333333]
step: 1350 	training acc: [0.33       0.32       0.33666667 0.31       0.34       0.36      ]
step: 1380 	training acc: [0.16333333 0.14       0.14333333 0.17       0.14333333 0.13      ]
step: 1410 	training acc: [0.16666667 0.19333333 0.17       0.16       0.16666667 0.14666667]
step: 1440 	training acc: [0.20666667 0.17333333 0.21       0.20333333 0.21       0.17333333]
step: 1470 	training acc: [0.15       0.16       0.15666667 0.14333333 0.14666667 0.13666667]
step: 1500 	training acc: [0.13333333 0.14       0.11666667 0.11666667 0.13       0.13      ]
Meta-test acc: [0.187  0.1898 0.1893 0.1904 0.1902 0.1876 0.1896 0.1918 0.1903 0.1868
 0.1896]
step: 1530 	training acc: [0.21666667 0.24       0.22666667 0.25       0.22666667 0.22333333]
step: 1560 	training acc: [0.17       0.14333333 0.14666667 0.15333333 0.13666667 0.17333333]
step: 1590 	training acc: [0.12333333 0.14       0.12       0.14666667 0.14       0.14333333]
step: 1620 	training acc: [0.22666667 0.19333333 0.19333333 0.2        0.19       0.17333333]
step: 1650 	training acc: [0.23333333 0.22666667 0.22666667 0.23       0.24666667 0.24666667]
step: 1680 	training acc: [0.14666667 0.11666667 0.11       0.12       0.12333333 0.12333333]
step: 1710 	training acc: [0.24333333 0.27666667 0.23       0.26       0.2        0.25666667]
step: 1740 	training acc: [0.17333333 0.17666667 0.17333333 0.16       0.18       0.15666667]
step: 1770 	training acc: [0.10666667 0.10333333 0.09       0.07666667 0.11       0.1       ]
step: 1800 	training acc: [0.27666667 0.31       0.27666667 0.29666667 0.30666667 0.30333333]
step: 1830 	training acc: [0.25666667 0.23666667 0.24333333 0.26       0.24666667 0.29      ]
step: 1860 	training acc: [0.09333333 0.11333333 0.10666667 0.1        0.09666667 0.11      ]
step: 1890 	training acc: [0.18333333 0.16333333 0.17       0.18       0.18333333 0.18333333]
step: 1920 	training acc: [0.22666667 0.23666667 0.27666667 0.23       0.26       0.26      ]
step: 1950 	training acc: [0.14       0.14       0.11333333 0.14       0.13666667 0.14333333]
step: 1980 	training acc: [0.22333333 0.26       0.23       0.26       0.24333333 0.23666667]
Meta-test acc: [0.2234 0.2185 0.2155 0.2275 0.2172 0.217  0.2201 0.2178 0.2124 0.2172
 0.2245]
step: 2010 	training acc: [0.19666667 0.19666667 0.19666667 0.17       0.15333333 0.17      ]
step: 2040 	training acc: [0.24333333 0.23333333 0.21666667 0.21       0.23333333 0.23333333]
step: 2070 	training acc: [0.16333333 0.17666667 0.18333333 0.19333333 0.18       0.17666667]
step: 2100 	training acc: [0.20666667 0.21       0.25333333 0.25       0.20666667 0.23333333]
step: 2130 	training acc: [0.09       0.13       0.11333333 0.11333333 0.12333333 0.12666667]
step: 2160 	training acc: [0.26666667 0.26       0.28666667 0.26333333 0.29333333 0.28333333]
step: 2190 	training acc: [0.13666667 0.14666667 0.14333333 0.14666667 0.15333333 0.17666667]
step: 2220 	training acc: [0.32       0.29       0.34       0.36       0.32666667 0.32666667]
step: 2250 	training acc: [0.35333333 0.35       0.34       0.31666667 0.34666667 0.35333333]
step: 2280 	training acc: [0.19333333 0.22666667 0.20333333 0.22       0.20666667 0.2       ]
step: 2310 	training acc: [0.19666667 0.16333333 0.18666667 0.17666667 0.15333333 0.21      ]
step: 2340 	training acc: [0.14333333 0.13       0.12666667 0.14       0.13333333 0.14      ]
step: 2370 	training acc: [0.28666667 0.26666667 0.29       0.26       0.26333333 0.29      ]
step: 2400 	training acc: [0.12333333 0.13       0.15333333 0.13333333 0.15666667 0.14666667]
step: 2430 	training acc: [0.2        0.21333333 0.19666667 0.18666667 0.19666667 0.18      ]
step: 2460 	training acc: [0.21       0.2        0.18333333 0.19666667 0.21333333 0.23333333]
step: 2490 	training acc: [0.18666667 0.17       0.18666667 0.18333333 0.17333333 0.19666667]
step: 0 	training acc: [0.19666667 0.20666667 0.2        0.20333333 0.18666667 0.21666667]
Meta-test acc: [0.1926 0.1989 0.1963 0.1962 0.195  0.1934 0.194  0.1908 0.1909 0.1906
 0.1979]
step: 30 	training acc: [0.13666667 0.14666667 0.11666667 0.14       0.16666667 0.15      ]
step: 60 	training acc: [0.15       0.14333333 0.18666667 0.16       0.15666667 0.15333333]
step: 90 	training acc: [0.18666667 0.15333333 0.18       0.15       0.21333333 0.14333333]
step: 120 	training acc: [0.16333333 0.19666667 0.15666667 0.17       0.16666667 0.15      ]
step: 150 	training acc: [0.21666667 0.23       0.21666667 0.23       0.24       0.21333333]
step: 180 	training acc: [0.25333333 0.23       0.24666667 0.25       0.23333333 0.29      ]
step: 210 	training acc: [0.17666667 0.17666667 0.16666667 0.18666667 0.15666667 0.18      ]
step: 240 	training acc: [0.24       0.23       0.25       0.22666667 0.22666667 0.19666667]
step: 270 	training acc: [0.24666667 0.25333333 0.18666667 0.26333333 0.25333333 0.22666667]
step: 300 	training acc: [0.23666667 0.24333333 0.26       0.23666667 0.25       0.22333333]
step: 330 	training acc: [0.19333333 0.18666667 0.19333333 0.22       0.17       0.2       ]
step: 360 	training acc: [0.26333333 0.24333333 0.22333333 0.22       0.25       0.25333333]
step: 390 	training acc: [0.16       0.15666667 0.14       0.17       0.17333333 0.16333333]
step: 420 	training acc: [0.12333333 0.10666667 0.10333333 0.1        0.12       0.12666667]
step: 450 	training acc: [0.24666667 0.24333333 0.25666667 0.22666667 0.25       0.24666667]
step: 480 	training acc: [0.23666667 0.21333333 0.26666667 0.23       0.20333333 0.23333333]
Meta-test acc: [0.2231 0.2192 0.2213 0.2185 0.2208 0.2213 0.218  0.217  0.2191 0.2201
 0.2216]
step: 510 	training acc: [0.2        0.21333333 0.19666667 0.2        0.21       0.21      ]
step: 540 	training acc: [0.17333333 0.19       0.18       0.19333333 0.19       0.19333333]
step: 570 	training acc: [0.19333333 0.21333333 0.21666667 0.21333333 0.20666667 0.19      ]
step: 600 	training acc: [0.12       0.14       0.13333333 0.13666667 0.12       0.14666667]
step: 630 	training acc: [0.28       0.29666667 0.27333333 0.24333333 0.30666667 0.27333333]
step: 660 	training acc: [0.23333333 0.24       0.22       0.23666667 0.23666667 0.22      ]
step: 690 	training acc: [0.2        0.18       0.21666667 0.22333333 0.19666667 0.20333333]
step: 720 	training acc: [0.19666667 0.2        0.21333333 0.17333333 0.20666667 0.21666667]
step: 750 	training acc: [0.21       0.23       0.24       0.23666667 0.24666667 0.21666667]
step: 780 	training acc: [0.12333333 0.13666667 0.12333333 0.13       0.11666667 0.14333333]
step: 810 	training acc: [0.24333333 0.25333333 0.25333333 0.27333333 0.27       0.28      ]
step: 840 	training acc: [0.17333333 0.17333333 0.17333333 0.15333333 0.21       0.16      ]
step: 870 	training acc: [0.25333333 0.24333333 0.19333333 0.24333333 0.25333333 0.22333333]
step: 900 	training acc: [0.17       0.18       0.18       0.19666667 0.15       0.19666667]
step: 930 	training acc: [0.22333333 0.23       0.22666667 0.20333333 0.21666667 0.21333333]
step: 960 	training acc: [0.04333333 0.05333333 0.05       0.07       0.05       0.06666667]
step: 990 	training acc: [0.28666667 0.27333333 0.30666667 0.28333333 0.29333333 0.29      ]
Meta-test acc: [0.1937 0.2013 0.1945 0.1962 0.1965 0.1959 0.1936 0.1941 0.1941 0.1932
 0.2018]
step: 1020 	training acc: [0.11       0.11333333 0.13       0.12666667 0.12       0.11333333]
step: 1050 	training acc: [0.28       0.3        0.24666667 0.3        0.31       0.26333333]
step: 1080 	training acc: [0.20333333 0.22       0.22666667 0.23       0.22       0.22666667]
step: 1110 	training acc: [0.11666667 0.12666667 0.14333333 0.11666667 0.12       0.14      ]
step: 1140 	training acc: [0.13       0.14333333 0.16       0.15666667 0.14333333 0.12666667]
step: 1170 	training acc: [0.27333333 0.26       0.25       0.25333333 0.24       0.21666667]
step: 1200 	training acc: [0.11333333 0.13666667 0.11333333 0.11       0.14666667 0.09666667]
step: 1230 	training acc: [0.19666667 0.19666667 0.18       0.17666667 0.19       0.18333333]
step: 1260 	training acc: [0.19       0.19333333 0.21666667 0.19333333 0.2        0.18333333]
step: 1290 	training acc: [0.11333333 0.14666667 0.16       0.16       0.12666667 0.15333333]
step: 1320 	training acc: [0.24666667 0.24666667 0.23666667 0.25666667 0.25       0.24333333]
step: 1350 	training acc: [0.15333333 0.13666667 0.15       0.12       0.12666667 0.13      ]
step: 1380 	training acc: [0.22       0.25       0.24       0.23333333 0.19333333 0.2       ]
step: 1410 	training acc: [0.12666667 0.11666667 0.12333333 0.10333333 0.12       0.11      ]
step: 1440 	training acc: [0.17333333 0.18       0.18333333 0.13666667 0.15666667 0.16      ]
step: 1470 	training acc: [0.18666667 0.18       0.17333333 0.2        0.18       0.2       ]
step: 1500 	training acc: [0.21666667 0.22666667 0.22333333 0.24666667 0.22       0.25666667]
Meta-test acc: [0.2078 0.2085 0.2085 0.212  0.2092 0.21   0.2123 0.2057 0.2084 0.2114
 0.2053]
step: 1530 	training acc: [0.16       0.18       0.14666667 0.14666667 0.14       0.13      ]
step: 1560 	training acc: [0.17       0.19       0.18333333 0.18       0.20333333 0.19      ]
step: 1590 	training acc: [0.27       0.26666667 0.26       0.28333333 0.31       0.27      ]
step: 1620 	training acc: [0.19666667 0.23       0.23333333 0.23       0.21333333 0.23666667]
step: 1650 	training acc: [0.10666667 0.13666667 0.10333333 0.09333333 0.14       0.12      ]
step: 1680 	training acc: [0.17333333 0.21666667 0.19666667 0.19       0.16       0.18333333]
step: 1710 	training acc: [0.21666667 0.2        0.19333333 0.20333333 0.18333333 0.21666667]
step: 1740 	training acc: [0.22       0.2        0.19       0.19       0.19333333 0.18333333]
step: 1770 	training acc: [0.21666667 0.24       0.22       0.22666667 0.22333333 0.23333333]
step: 1800 	training acc: [0.18666667 0.20666667 0.19666667 0.19333333 0.19333333 0.19666667]
step: 1830 	training acc: [0.23666667 0.25333333 0.21666667 0.28       0.23333333 0.25333333]
step: 1860 	training acc: [0.10333333 0.10666667 0.13       0.15       0.10666667 0.11      ]
step: 1890 	training acc: [0.26666667 0.29333333 0.27333333 0.28       0.27       0.28333333]
step: 1920 	training acc: [0.26666667 0.26       0.28333333 0.29       0.25333333 0.26666667]
step: 1950 	training acc: [0.20666667 0.20666667 0.23       0.19       0.2        0.19      ]
step: 1980 	training acc: [0.17       0.21666667 0.15666667 0.20666667 0.18666667 0.21      ]
Meta-test acc: [0.1847 0.187  0.1853 0.1887 0.1898 0.1891 0.1866 0.1875 0.1923 0.1908
 0.1858]
step: 2010 	training acc: [0.17       0.16333333 0.17333333 0.16666667 0.13666667 0.15666667]
step: 2040 	training acc: [0.22333333 0.21333333 0.20333333 0.19666667 0.17666667 0.22      ]
step: 2070 	training acc: [0.26666667 0.26333333 0.26666667 0.26       0.27666667 0.24333333]
step: 2100 	training acc: [0.23       0.25       0.24       0.26666667 0.24       0.27333333]
step: 2130 	training acc: [0.18333333 0.23       0.18666667 0.17       0.17666667 0.16      ]
step: 2160 	training acc: [0.12333333 0.13       0.15       0.13       0.13       0.14666667]
step: 2190 	training acc: [0.13666667 0.13666667 0.09       0.11333333 0.10666667 0.12      ]
step: 2220 	training acc: [0.07333333 0.08666667 0.06666667 0.06666667 0.07333333 0.06666667]
step: 2250 	training acc: [0.21       0.17333333 0.18       0.22       0.19       0.18666667]
step: 2280 	training acc: [0.21       0.20666667 0.20666667 0.20666667 0.19666667 0.2       ]
step: 2310 	training acc: [0.22333333 0.18333333 0.21666667 0.20333333 0.2        0.20666667]
step: 2340 	training acc: [0.23       0.23333333 0.21       0.23666667 0.23       0.21      ]
step: 2370 	training acc: [0.15333333 0.15333333 0.13666667 0.16333333 0.14       0.10333333]
step: 2400 	training acc: [0.27       0.29       0.24666667 0.21333333 0.26666667 0.24333333]
step: 2430 	training acc: [0.20666667 0.21666667 0.24       0.20666667 0.20666667 0.18666667]
step: 2460 	training acc: [0.24333333 0.23       0.27       0.22       0.27       0.25666667]
step: 2490 	training acc: [0.18333333 0.18       0.2        0.20333333 0.21333333 0.21333333]
step: 0 	training acc: [0.16666667 0.19       0.16666667 0.19666667 0.15       0.18666667]
Meta-test acc: [0.2047 0.2006 0.2032 0.2104 0.2062 0.1978 0.2046 0.2024 0.2041 0.2017
 0.2031]
step: 30 	training acc: [0.34333333 0.35666667 0.34333333 0.34666667 0.33666667 0.33666667]
step: 60 	training acc: [0.14666667 0.13666667 0.14       0.12666667 0.15333333 0.16      ]
step: 90 	training acc: [0.26333333 0.27333333 0.26333333 0.25666667 0.26       0.22      ]
step: 120 	training acc: [0.20666667 0.17666667 0.17       0.22666667 0.17       0.16666667]
step: 150 	training acc: [0.24333333 0.26666667 0.24666667 0.25666667 0.25       0.23333333]
step: 180 	training acc: [0.19       0.18       0.17666667 0.19666667 0.20666667 0.18333333]
step: 210 	training acc: [0.31333333 0.29       0.30666667 0.28       0.30333333 0.31666667]
step: 240 	training acc: [0.23333333 0.25333333 0.25       0.25333333 0.25666667 0.23333333]
step: 270 	training acc: [0.24333333 0.26       0.26333333 0.25       0.27333333 0.26333333]
step: 300 	training acc: [0.15       0.15333333 0.18333333 0.14333333 0.15666667 0.13666667]
step: 330 	training acc: [0.19333333 0.17333333 0.20333333 0.20666667 0.20666667 0.17333333]
step: 360 	training acc: [0.29666667 0.29333333 0.27       0.24       0.26666667 0.29      ]
step: 390 	training acc: [0.16333333 0.18       0.17333333 0.20666667 0.20666667 0.17333333]
step: 420 	training acc: [0.25666667 0.3        0.28       0.27       0.26       0.27333333]
step: 450 	training acc: [0.41       0.42333333 0.44       0.42       0.43666667 0.42      ]
step: 480 	training acc: [0.28       0.28333333 0.26666667 0.29333333 0.26666667 0.29      ]
Meta-test acc: [0.1995 0.1992 0.1992 0.2041 0.2079 0.2001 0.2021 0.1996 0.1997 0.198
 0.1981]
step: 510 	training acc: [0.07333333 0.08       0.09666667 0.07333333 0.09666667 0.1       ]
step: 540 	training acc: [0.14666667 0.12       0.13       0.13666667 0.16       0.14      ]
step: 570 	training acc: [0.13666667 0.16333333 0.15       0.17666667 0.13333333 0.13666667]
step: 600 	training acc: [0.19       0.16333333 0.16666667 0.2        0.18666667 0.2       ]
step: 630 	training acc: [0.2        0.19666667 0.17       0.17666667 0.19       0.19333333]
step: 660 	training acc: [0.19333333 0.16333333 0.22333333 0.19333333 0.2        0.17666667]
step: 690 	training acc: [0.13666667 0.12       0.12       0.15333333 0.12333333 0.12666667]
step: 720 	training acc: [0.22333333 0.21333333 0.22       0.24333333 0.23666667 0.21333333]
step: 750 	training acc: [0.25       0.26       0.26333333 0.25       0.25       0.27333333]
step: 780 	training acc: [0.23       0.22333333 0.22       0.21333333 0.21333333 0.2       ]
step: 810 	training acc: [0.25666667 0.25333333 0.24666667 0.22333333 0.25666667 0.23      ]
step: 840 	training acc: [0.24666667 0.23       0.23333333 0.25333333 0.25333333 0.25333333]
step: 870 	training acc: [0.19       0.21       0.17666667 0.18       0.16666667 0.17333333]
step: 900 	training acc: [0.22333333 0.16333333 0.22       0.14333333 0.20666667 0.17      ]
step: 930 	training acc: [0.19       0.20333333 0.22       0.21666667 0.21       0.24333333]
step: 960 	training acc: [0.23666667 0.21333333 0.28666667 0.24333333 0.25666667 0.21666667]
step: 990 	training acc: [0.27       0.25       0.27333333 0.29       0.24       0.26      ]
Meta-test acc: [0.1995 0.2004 0.2031 0.2003 0.1947 0.1975 0.1914 0.196  0.1885 0.2028
 0.1965]
step: 1020 	training acc: [0.21666667 0.21666667 0.22666667 0.24666667 0.20666667 0.25333333]
step: 1050 	training acc: [0.26333333 0.25       0.27333333 0.25666667 0.27666667 0.25      ]
step: 1080 	training acc: [0.40333333 0.37333333 0.39666667 0.40333333 0.41333333 0.39333333]
step: 1110 	training acc: [0.22333333 0.24666667 0.21       0.20666667 0.21333333 0.21666667]
step: 1140 	training acc: [0.14333333 0.15666667 0.16333333 0.16666667 0.14666667 0.12333333]
step: 1170 	training acc: [0.16       0.15333333 0.11       0.14       0.15666667 0.15666667]
step: 1200 	training acc: [0.16333333 0.15       0.18333333 0.16666667 0.16333333 0.16666667]
step: 1230 	training acc: [0.16666667 0.14666667 0.17       0.14       0.18333333 0.16      ]
step: 1260 	training acc: [0.18666667 0.16333333 0.17333333 0.16       0.15333333 0.17333333]
step: 1290 	training acc: [0.18333333 0.14666667 0.17333333 0.17333333 0.15666667 0.12333333]
step: 1320 	training acc: [0.18       0.18       0.15666667 0.17666667 0.16666667 0.15666667]
step: 1350 	training acc: [0.24666667 0.23       0.22666667 0.23666667 0.24333333 0.23333333]
step: 1380 	training acc: [0.16       0.16       0.17666667 0.16333333 0.17       0.13333333]
step: 1410 	training acc: [0.25       0.28       0.24333333 0.27       0.29666667 0.29333333]
step: 1440 	training acc: [0.26666667 0.25666667 0.29       0.27666667 0.25333333 0.25333333]
step: 1470 	training acc: [0.18666667 0.14666667 0.18333333 0.19       0.19       0.17666667]
step: 1500 	training acc: [0.27333333 0.25       0.25       0.26       0.25666667 0.23666667]
Meta-test acc: [0.1816 0.1793 0.1826 0.1761 0.1815 0.1821 0.1788 0.1846 0.1792 0.1825
 0.183 ]
step: 1530 	training acc: [0.13       0.13333333 0.10666667 0.12333333 0.13       0.11      ]
step: 1560 	training acc: [0.22666667 0.25       0.24333333 0.25       0.24666667 0.24333333]
step: 1590 	training acc: [0.26       0.26666667 0.29333333 0.30333333 0.29666667 0.25333333]
step: 1620 	training acc: [0.23       0.16       0.17       0.15333333 0.20666667 0.16      ]
step: 1650 	training acc: [0.13       0.17666667 0.19333333 0.13       0.15333333 0.17      ]
step: 1680 	training acc: [0.14666667 0.16666667 0.18333333 0.19666667 0.2        0.18      ]
step: 1710 	training acc: [0.14       0.14       0.15666667 0.12666667 0.15       0.14333333]
step: 1740 	training acc: [0.31666667 0.32666667 0.32       0.31666667 0.32333333 0.32      ]
step: 1770 	training acc: [0.25       0.21666667 0.23666667 0.22333333 0.24       0.26      ]
step: 1800 	training acc: [0.17333333 0.21666667 0.16666667 0.21       0.19666667 0.22333333]
step: 1830 	training acc: [0.24666667 0.28666667 0.27333333 0.25666667 0.28666667 0.26333333]
step: 1860 	training acc: [0.17333333 0.16666667 0.23666667 0.14666667 0.18666667 0.17333333]
step: 1890 	training acc: [0.17       0.14666667 0.16       0.15666667 0.17666667 0.14333333]
step: 1920 	training acc: [0.20666667 0.20666667 0.22333333 0.21666667 0.2        0.23333333]
step: 1950 	training acc: [0.21333333 0.22666667 0.21333333 0.21333333 0.20333333 0.23666667]
step: 1980 	training acc: [0.25       0.26666667 0.22666667 0.24333333 0.21666667 0.24666667]
Meta-test acc: [0.2269 0.2261 0.2279 0.2251 0.2311 0.2291 0.234  0.2258 0.225  0.2299
 0.2283]
step: 2010 	training acc: [0.26666667 0.27333333 0.30333333 0.3        0.26666667 0.26333333]
step: 2040 	training acc: [0.16       0.15333333 0.15666667 0.16333333 0.15666667 0.15666667]
step: 2070 	training acc: [0.19666667 0.21333333 0.19333333 0.23333333 0.2        0.22333333]
step: 2100 	training acc: [0.20666667 0.22666667 0.21333333 0.19333333 0.22       0.21333333]
step: 2130 	training acc: [0.09       0.09333333 0.08666667 0.08       0.08666667 0.09333333]
step: 2160 	training acc: [0.25666667 0.22666667 0.22333333 0.25333333 0.25333333 0.25333333]
step: 2190 	training acc: [0.17333333 0.16333333 0.18       0.16       0.17       0.17666667]
step: 2220 	training acc: [0.12666667 0.10333333 0.11666667 0.11333333 0.13333333 0.09333333]
step: 2250 	training acc: [0.26666667 0.19333333 0.26       0.21333333 0.21       0.24666667]
step: 2280 	training acc: [0.20666667 0.22666667 0.18       0.16333333 0.23666667 0.19      ]
step: 2310 	training acc: [0.29666667 0.34333333 0.30333333 0.3        0.29666667 0.32333333]
step: 2340 	training acc: [0.25666667 0.24       0.24       0.21666667 0.25333333 0.25      ]
step: 2370 	training acc: [0.19333333 0.19       0.22333333 0.17333333 0.20333333 0.18333333]
step: 2400 	training acc: [0.12666667 0.09       0.11666667 0.14333333 0.10333333 0.13333333]
step: 2430 	training acc: [0.19666667 0.21       0.22333333 0.17333333 0.22333333 0.19666667]
step: 2460 	training acc: [0.22333333 0.23666667 0.22       0.24       0.21       0.21333333]
step: 2490 	training acc: [0.16666667 0.20333333 0.19       0.19333333 0.18333333 0.18666667]
step: 0 	training acc: [0.10333333 0.14       0.12333333 0.11333333 0.11       0.12333333]
Meta-test acc: [0.196  0.199  0.1934 0.2014 0.1995 0.1985 0.1908 0.1975 0.1953 0.2008
 0.2029]
step: 30 	training acc: [0.25       0.23333333 0.22       0.22333333 0.24       0.21666667]
step: 60 	training acc: [0.13666667 0.16666667 0.12666667 0.14333333 0.17333333 0.17      ]
step: 90 	training acc: [0.19666667 0.20666667 0.19       0.19666667 0.16333333 0.20666667]
step: 120 	training acc: [0.20666667 0.20333333 0.20666667 0.2        0.19333333 0.21666667]
step: 150 	training acc: [0.14666667 0.15       0.14666667 0.14333333 0.14666667 0.15333333]
step: 180 	training acc: [0.37333333 0.37       0.35333333 0.35333333 0.37333333 0.35333333]
step: 210 	training acc: [0.42       0.40666667 0.42333333 0.41333333 0.39666667 0.4       ]
step: 240 	training acc: [0.22       0.21333333 0.23333333 0.21       0.21666667 0.19333333]
step: 270 	training acc: [0.16333333 0.16666667 0.19666667 0.19666667 0.17333333 0.15666667]
step: 300 	training acc: [0.22666667 0.22333333 0.21666667 0.21666667 0.19666667 0.21      ]
step: 330 	training acc: [0.29333333 0.27       0.3        0.31333333 0.30333333 0.27333333]
step: 360 	training acc: [0.18666667 0.18333333 0.19666667 0.17333333 0.18666667 0.16      ]
step: 390 	training acc: [0.22       0.19       0.20333333 0.15666667 0.17333333 0.18333333]
step: 420 	training acc: [0.23       0.24333333 0.26666667 0.25       0.24       0.25333333]
step: 450 	training acc: [0.17       0.17666667 0.15666667 0.14666667 0.14333333 0.16      ]
step: 480 	training acc: [0.10333333 0.12666667 0.09666667 0.13       0.12666667 0.14666667]
Meta-test acc: [0.1931 0.1925 0.1897 0.1962 0.191  0.1865 0.1924 0.1919 0.1945 0.1938
 0.19  ]
step: 510 	training acc: [0.09666667 0.08666667 0.08333333 0.07666667 0.1        0.11      ]
step: 540 	training acc: [0.24       0.24       0.21666667 0.21333333 0.22666667 0.21333333]
step: 570 	training acc: [0.24       0.23333333 0.28333333 0.26       0.24       0.25666667]
step: 600 	training acc: [0.25333333 0.22333333 0.25333333 0.26       0.27       0.27      ]
step: 630 	training acc: [0.19666667 0.22       0.21       0.22666667 0.22333333 0.21666667]
step: 660 	training acc: [0.24       0.27       0.26       0.26333333 0.22666667 0.24      ]
step: 690 	training acc: [0.13       0.12       0.10666667 0.11666667 0.12666667 0.12      ]
step: 720 	training acc: [0.15333333 0.18       0.17333333 0.14666667 0.15       0.15333333]
step: 750 	training acc: [0.09333333 0.08666667 0.08666667 0.07       0.06333333 0.06666667]
step: 780 	training acc: [0.16       0.17666667 0.18666667 0.15666667 0.14666667 0.18666667]
step: 810 	training acc: [0.29       0.29333333 0.33333333 0.29333333 0.26333333 0.3       ]
step: 840 	training acc: [0.20333333 0.2        0.21       0.17666667 0.16666667 0.19      ]
step: 870 	training acc: [0.21       0.22333333 0.20333333 0.21333333 0.20666667 0.20333333]
step: 900 	training acc: [0.14       0.15333333 0.13333333 0.13333333 0.12       0.12333333]
step: 930 	training acc: [0.25       0.26333333 0.23666667 0.26333333 0.24333333 0.25333333]
step: 960 	training acc: [0.30333333 0.30666667 0.30333333 0.30333333 0.29666667 0.32666667]
step: 990 	training acc: [0.09333333 0.10333333 0.10666667 0.10333333 0.08333333 0.08666667]
Meta-test acc: [0.1956 0.199  0.1982 0.195  0.1946 0.1896 0.1937 0.1954 0.1956 0.1959
 0.1902]
step: 1020 	training acc: [0.19333333 0.17333333 0.17333333 0.18       0.20666667 0.17666667]
step: 1050 	training acc: [0.13666667 0.14       0.14333333 0.12666667 0.11333333 0.12      ]
step: 1080 	training acc: [0.11666667 0.13       0.09666667 0.09666667 0.10333333 0.1       ]
step: 1110 	training acc: [0.19       0.18       0.21333333 0.2        0.21666667 0.19      ]
step: 1140 	training acc: [0.21333333 0.22       0.21333333 0.23       0.22333333 0.22      ]
step: 1170 	training acc: [0.24333333 0.24666667 0.24       0.22666667 0.21666667 0.23333333]
step: 1200 	training acc: [0.21333333 0.24333333 0.21333333 0.21       0.21666667 0.24333333]
step: 1230 	training acc: [0.24       0.21       0.23333333 0.21666667 0.18333333 0.22      ]
step: 1260 	training acc: [0.16333333 0.17666667 0.22       0.18       0.23666667 0.23      ]
step: 1290 	training acc: [0.09666667 0.11666667 0.11       0.09666667 0.13       0.12333333]
step: 1320 	training acc: [0.11       0.12       0.11       0.10333333 0.11666667 0.10333333]
step: 1350 	training acc: [0.18       0.18666667 0.18       0.17       0.18       0.18      ]
step: 1380 	training acc: [0.22333333 0.21333333 0.20666667 0.21       0.22333333 0.21333333]
step: 1410 	training acc: [0.27333333 0.27       0.25666667 0.32       0.31333333 0.24      ]
step: 1440 	training acc: [0.14333333 0.14666667 0.11333333 0.12666667 0.14333333 0.13333333]
step: 1470 	training acc: [0.36666667 0.33       0.32666667 0.34       0.32666667 0.32333333]
step: 1500 	training acc: [0.23       0.21666667 0.24       0.24       0.25333333 0.26      ]
Meta-test acc: [0.2115 0.2129 0.2083 0.2123 0.2122 0.2135 0.2086 0.2129 0.2181 0.2134
 0.2179]
step: 1530 	training acc: [0.15666667 0.16666667 0.17666667 0.14666667 0.15333333 0.16      ]
step: 1560 	training acc: [0.19333333 0.15666667 0.21666667 0.16333333 0.17666667 0.18333333]
step: 1590 	training acc: [0.15       0.12666667 0.18       0.15333333 0.16666667 0.15      ]
step: 1620 	training acc: [0.11333333 0.11666667 0.10333333 0.10666667 0.11666667 0.11      ]
step: 1650 	training acc: [0.18666667 0.19       0.16333333 0.16666667 0.15333333 0.13666667]
step: 1680 	training acc: [0.18333333 0.19       0.18       0.16666667 0.19666667 0.16      ]
step: 1710 	training acc: [0.14666667 0.17666667 0.17666667 0.16333333 0.15333333 0.18333333]
step: 1740 	training acc: [0.18333333 0.19666667 0.17       0.22       0.19       0.21      ]
step: 1770 	training acc: [0.22       0.22       0.23333333 0.21       0.19666667 0.25      ]
step: 1800 	training acc: [0.18       0.21       0.19333333 0.18666667 0.16666667 0.18      ]
step: 1830 	training acc: [0.13333333 0.17666667 0.17666667 0.18333333 0.14333333 0.17666667]
step: 1860 	training acc: [0.16333333 0.21       0.17333333 0.18333333 0.18       0.17      ]
step: 1890 	training acc: [0.17       0.15333333 0.15666667 0.17666667 0.16333333 0.15333333]
step: 1920 	training acc: [0.08333333 0.09       0.08333333 0.08       0.06666667 0.06333333]
step: 1950 	training acc: [0.24       0.26666667 0.24       0.26333333 0.24666667 0.27333333]
step: 1980 	training acc: [0.1        0.10333333 0.09333333 0.1        0.15       0.10666667]
Meta-test acc: [0.1985 0.1924 0.1982 0.1975 0.1956 0.194  0.191  0.1975 0.191  0.198
 0.1936]
step: 2010 	training acc: [0.17333333 0.20333333 0.15333333 0.2        0.18666667 0.18      ]
step: 2040 	training acc: [0.19333333 0.19333333 0.23333333 0.21       0.21333333 0.21333333]
step: 2070 	training acc: [0.24       0.26       0.22666667 0.25666667 0.26333333 0.25333333]
step: 2100 	training acc: [0.22       0.23       0.22666667 0.23666667 0.24666667 0.21666667]
step: 2130 	training acc: [0.05666667 0.06666667 0.07       0.07       0.06       0.05333333]
step: 2160 	training acc: [0.36333333 0.35333333 0.34       0.35333333 0.35       0.34333333]
step: 2190 	training acc: [0.17666667 0.17333333 0.24       0.2        0.22       0.19      ]
step: 2220 	training acc: [0.29       0.25333333 0.26333333 0.26       0.27       0.27      ]
step: 2250 	training acc: [0.20333333 0.16666667 0.21333333 0.20666667 0.18333333 0.17333333]
step: 2280 	training acc: [0.11666667 0.11333333 0.11333333 0.11333333 0.12666667 0.11666667]
step: 2310 	training acc: [0.18       0.19333333 0.18       0.20333333 0.2        0.16666667]
step: 2340 	training acc: [0.19333333 0.2        0.14666667 0.14333333 0.17       0.17      ]
step: 2370 	training acc: [0.28333333 0.28666667 0.28666667 0.3        0.26       0.30333333]
step: 2400 	training acc: [0.13333333 0.11       0.13666667 0.09       0.12666667 0.12      ]
step: 2430 	training acc: [0.32       0.30666667 0.32333333 0.27333333 0.28       0.26666667]
step: 2460 	training acc: [0.28       0.23333333 0.25666667 0.26       0.25666667 0.27666667]
step: 2490 	training acc: [0.25333333 0.24666667 0.24333333 0.25       0.25333333 0.28666667]
final evaluation
mean acc 0.2015
median acc 0.1982
std acc 0.11
max acc 0.5186
min acc 0.003637
